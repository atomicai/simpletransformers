{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import unittest\n",
    "from pathlib import Path\n",
    "from typing import Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import simplejson\n",
    "import torch\n",
    "from transformers import MBart50Tokenizer, MBartForConditionalGeneration\n",
    "\n",
    "from simpletransformers.config import model_args as simpleconifg\n",
    "from simpletransformers.seq2seq import Seq2SeqModel\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(\n",
    "    data_dir: Union[Path, str],\n",
    "    filename: str,\n",
    "    embedding_field=\"embedding\",\n",
    "    load_embedding=True,\n",
    "    ext=\".json\",\n",
    "    parse_meta: bool = False,\n",
    "    lazy: bool = False,\n",
    "    sep: str = \",\",\n",
    "    encoding: str = \"utf-8-sig\",\n",
    "    as_record: bool = False,\n",
    "    rename_columns: dict = None,\n",
    "    engine: str = \"pandas\",\n",
    "    **kwargs,\n",
    "):\n",
    "    assert engine in (\"pandas\", \"polars\")\n",
    "    if engine == \"polars\":\n",
    "        import polars as pd\n",
    "    else:\n",
    "        import pandas as pd\n",
    "    data_dir = Path(data_dir)\n",
    "    db_filename = filename\n",
    "    db_filepath = data_dir / (db_filename + ext)\n",
    "\n",
    "    if ext in (\".csv\", \".tsv\", \".xlsx\", \".pickle\", \".gz\"):\n",
    "        columns_needed = list(rename_columns.keys()) if rename_columns else None\n",
    "        if ext == \".xlsx\":\n",
    "            df = pd.read_excel(db_filepath, engine=\"openpyxl\") if engine == \"pandas\" else pd.read_excel(db_filepath)\n",
    "        elif ext in (\".tsv\", \".csv\"):\n",
    "            if engine == \"pandas\":\n",
    "                df = pd.read_csv(\n",
    "                    db_filepath, encoding=encoding, usecols=columns_needed, skipinitialspace=True, sep=sep, **kwargs\n",
    "                )\n",
    "            else:\n",
    "                df = pd.read_csv(db_filepath, encoding=encoding, sep=sep)\n",
    "                df = df[columns_needed] if columns_needed else df\n",
    "        elif ext in (\".pickle\"):\n",
    "            df = pd.read_pickle(db_filepath, **kwargs)\n",
    "        else:\n",
    "            df = pd.read_csv(db_filepath, header=0, error_bad_lines=False, **kwargs)\n",
    "        if rename_columns is not None:\n",
    "            df = df.rename(rename_columns) if rename_columns else df\n",
    "        if as_record:\n",
    "            yield df.to_dict(orient=\"records\")\n",
    "        else:\n",
    "            yield df\n",
    "        raise StopIteration()\n",
    "    with open(str(db_filepath), \"r\", encoding=encoding) as j_ptr:\n",
    "        if lazy:\n",
    "            for jline in j_ptr:\n",
    "                yield simplejson.loads(jline)\n",
    "        else:\n",
    "            docs = simplejson.load(j_ptr)\n",
    "\n",
    "    if lazy:\n",
    "        raise StopIteration()\n",
    "\n",
    "    if parse_meta:\n",
    "        for d in docs:\n",
    "            d[\"meta\"] = ast.literal_eval(d[\"meta\"])\n",
    "\n",
    "    if embedding_field is not None:\n",
    "        if load_embedding:\n",
    "            index_filename = filename + \"_index\" + \".npy\"\n",
    "            index_filepath = data_dir / index_filename\n",
    "            embeddings = np.load(str(index_filepath))\n",
    "            for iDoc, iEmb in zip(docs, embeddings):\n",
    "                iDoc[embedding_field] = iEmb\n",
    "        else:\n",
    "            for iDoc in docs:\n",
    "                iDoc[embedding_field] = np.nan\n",
    "\n",
    "    yield docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formify(x):\n",
    "    return str(x).startswith(\"abstractive\")\n",
    "\n",
    "\n",
    "def unify(x):\n",
    "    query, context = x[0], x[1]\n",
    "    print(query.shape)\n",
    "    print(context.shape)\n",
    "    return query + \" \" + context\n",
    "\n",
    "\n",
    "def answerify(x):\n",
    "    return str(x)[len(\"answer:\") :].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_matches(labels, preds):\n",
    "    return sum([1 if label == pred else 0 for label, pred in zip(labels, preds)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path.home() / \"IDataset\" / \"dlabel\"\n",
    "filename = Path(\"ru451.csv\")\n",
    "\n",
    "model_name = \"facebook/mbart-large-50\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = {\n",
    "    \"model_name\": f\"{model_name}\",\n",
    "    \"model_type\": \"mbart50\",\n",
    "    \"reprocess_input_data\": True,\n",
    "    \"overwrite_output_dir\": True,\n",
    "    \"max_seq_length\": 128,  # DECODER target length as max_generated sequence since (`len(decoder_input_ids) == len(labels)`)\n",
    "    \"train_batch_size\": 16,\n",
    "    \"eval_batch_size\": 16,\n",
    "    \"num_train_epochs\": 1,\n",
    "    \"save_eval_checkpoints\": False,\n",
    "    \"save_model_every_epoch\": False,\n",
    "    # \"silent\": True,\n",
    "    \"evaluate_generated_text\": True,\n",
    "    \"evaluate_during_training\": True,\n",
    "    \"evaluate_during_training_verbose\": True,\n",
    "    \"use_multiprocessing\": False,\n",
    "    \"save_best_model\": True,\n",
    "    \"max_length\": 256,  # ENCODER input length. (`len(input_ids)`)\n",
    "    \"src_lang\": \"ru_RU\",\n",
    "    \"tgt_lang\": \"ru_RU\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = next(get_data(data_dir=data_dir, filename=filename.stem, ext=filename.suffix, engine=\"polars\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99,)\n",
      "(99,)\n"
     ]
    }
   ],
   "source": [
    "df = (\n",
    "            df.with_columns([pl.col(\"format\").apply(formify).alias(\"mask\")])\n",
    "            .filter(pl.col(\"mask\"))\n",
    "            .drop(\"mask\")\n",
    "            .with_columns([pl.map([\"query\", \"context\"], unify).alias(\"text\")])\n",
    "            .with_columns([pl.col(\"answer\").apply(answerify).alias(\"target\")])\n",
    "            .drop([\"query\", \"context\", \"answer\", \"format\", \"label\"])\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text, target = [str(x) for x in list(df.select(\"text\").to_arrow()[\"text\"])], [str(x) for x in df.select(\"target\").to_arrow()[\"target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [[x, y] for x, y in zip(text, target)]\n",
    "train_df = pd.DataFrame(train_data, columns=[\"input_text\", \"target_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>target_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>query: Как Кларисса Маклеллан догадалась о про...</td>\n",
       "      <td>При первой встрече Монтэга и Клариссы Маклелла...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>query: Почему при встрече с Монтэгом, Кларисса...</td>\n",
       "      <td>По советом своего дяди, Кларисса ответила Монт...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>query: Какое прекрасное чувство ощутил Гай, ко...</td>\n",
       "      <td>В это мгновение Гай почувствовал невероятную т...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>query: По какой причине, Монтэг сказал Кларисс...</td>\n",
       "      <td>Во время их первой встречи, Кларисса задает мн...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>query: Почему у Клариссы было очень много мысл...</td>\n",
       "      <td>Кларисса не проводила свое время как все остал...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          input_text  \\\n",
       "0  query: Как Кларисса Маклеллан догадалась о про...   \n",
       "1  query: Почему при встрече с Монтэгом, Кларисса...   \n",
       "2  query: Какое прекрасное чувство ощутил Гай, ко...   \n",
       "3  query: По какой причине, Монтэг сказал Кларисс...   \n",
       "4  query: Почему у Клариссы было очень много мысл...   \n",
       "\n",
       "                                         target_text  \n",
       "0  При первой встрече Монтэга и Клариссы Маклелла...  \n",
       "1  По советом своего дяди, Кларисса ответила Монт...  \n",
       "2  В это мгновение Гай почувствовал невероятную т...  \n",
       "3  Во время их первой встречи, Кларисса задает мн...  \n",
       "4  Кларисса не проводила свое время как все остал...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2SeqModel(\n",
    "            encoder_decoder_type=\"mbart50\", encoder_decoder_name=model_name, use_cuda=torch.cuda.is_available(), args=model_args\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7,\n",
       " {'global_step': [7],\n",
       "  'eval_loss': [3.402956792286464],\n",
       "  'train_loss': [3.587454319000244],\n",
       "  'matches': [0]})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train_model(train_df, eval_data=train_df, matches=count_matches) # This is just one epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c38ac97849b04e79b198edcbfaeadde6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating outputs:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = model.eval_model(train_df, matches=count_matches) # You can pass any function accepting preds | labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 3.402956792286464, 'matches': 0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"query: Почему у Клариссы было очень много мыслей в голове, касающиеся правильности настоящей жизни в книге «451 градусов по Фаренгейту»?\"\n",
    "context = \"context: — Вы слишком много думаете, — заметил Монтэг, испытывая неловкость.  — Я редко смотрю телевизионные передачи, и не бываю на автомобильных гонках, и не хожу в парки развлечений. Вот у меня и остается время для всяких сумасбродных мыслей. Вы видели на шоссе за городом рекламные щиты? Сейчас они длиной в двести футов. А знаете ли вы, что когда-то они были длиной всего в двадцать футов? Но теперь автомобили несутся по дорогам с такой скоростью, что рекламы пришлось удлинить, а то их никто и прочитать бы не смог.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1cbf4b5246b41129280f8dea78f8e36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating outputs:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['query: Почему у Клариссы было очень много мыслей в голове, касающиеся правильности настоящей жизни в книге «451 градусов по Фаренгейту»?context: — Вы слишком много думаете, — заметил Монтэг, испытывая неловкость. — Я редко смотрю телевизионные передачи, и не бываю на автомобильных гонках, и не хожу в парки развлечений. Вот у меня и остается время для всяких сумасбродных мыслей. Вы видели на шоссе за городом рекламные щиты? Сейчас']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([query + context])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Later on you can always load the best one using..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2SeqModel(encoder_decoder_type=\"mbart50\", encoder_decoder_name=\"outputs/best_model\", use_cuda=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert model.model.training is False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecd6fb1391e947468e8a67fb28dfdb9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating outputs:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['query: Почему у Клариссы было очень много мыслей в голове, касающиеся правильности настоящей жизни в книге «451 градусов по Фаренгейту»?context: — Вы слишком много думаете, — заметил Монтэг, испытывая неловкость. — Я редко смотрю телевизионные передачи, и не бываю на автомобильных гонках, и не хожу в парки развлечений. Вот у меня и остается время для всяких сумасбродных мыслей. Вы видели на шоссе за городом рекламные щиты? Сейчас']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([query + context])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "patronum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6f68d56d791dc919179892de552f395b80e54ba38105afe06f1452ab1f77b07"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
